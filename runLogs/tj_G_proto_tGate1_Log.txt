env action space is:  Discrete(2)
num inputs is:  17
[2]
[2, 2]
Namespace(num_epochs=2000, epoch_size=10, batch_size=500, nprocesses=16, hid_size=128, recurrent=True, gamma=1.0, tau=1.0, seed=777, normalize_rewards=False, lrate=0.001, entr=0, value_coeff=0.01, env_name='traffic_junction', max_steps=20, nactions='1', action_scale=1.0, plot=False, plot_env='main', save='trained_models', save_every=100, load='trained_models', display=False, random=False, commnet=1, ic3net=True, nagents=5, comm_mode='avg', comm_passes=1, comm_mask_zero=False, mean_ratio=0, rnn_type='LSTM', detach_gap=10, comm_init='uniform', hard_attn=1, comm_action_one=False, comm_action_zero=False, advantages_per_action=False, share_weights=False, log_dir='tb_logs', exp_name='tj_G_proto_tGate1_', use_proto=True, discrete_comm=True, num_proto=25, comm_dim=16, gating_head_cost_factor=-0.1, restore=False, gate_reward_curriculum=False, gate_reward_max=-0.01, gate_reward_min=0.01, reward_curr_start=1500, reward_curr_end=1900, variable_gate=True, variable_gate_start=500, dim=6, vision=0, add_rate_min=0.1, add_rate_max=0.3, curr_start=250.0, curr_end=1250.0, difficulty='easy', vocab_type='bool', nfriendly=5, num_actions=[2, 2], dim_actions=2, num_inputs=17, continuous=False, naction_heads=[2, 2])
using commnet
====================================================================================================
Model log:

CommNetMLP(
  (proto_layer): ProtoNetwork(
    (layers): ModuleList(
      (0): Linear(in_features=128, out_features=64, bias=True)
      (1): Linear(in_features=64, out_features=25, bias=True)
    )
    (prototype_layer): ProtoLayer()
  )
  (heads): ModuleList(
    (0): Linear(in_features=128, out_features=2, bias=True)
    (1): Linear(in_features=128, out_features=2, bias=True)
  )
  (encoder): Linear(in_features=17, out_features=16, bias=True)
  (hidd_encoder): Linear(in_features=128, out_features=128, bias=True)
  (f_module): LSTMCell(16, 128)
  (C_modules): ModuleList(
    (0): Linear(in_features=16, out_features=16, bias=True)
  )
  (tanh): Tanh()
  (value_head): Linear(in_features=128, out_features=1, bias=True)
)
====================================================================================================

Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETADevice: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
save directory is trained_models/traffic_junction/tj_G_proto_tGate1_/seed20/models
log dir directory is trained_models/traffic_junction/tj_G_proto_tGate1_/seed20/logs
Epoch 0	Reward [-4.72 -4.93 -4.86 -4.99 -5.05]	Time 86.92s
Add-Rate: 0.10
Success: 0.69
Steps-taken: 20.00
Comm-Action: [0.52 0.52 0.52 0.52 0.52]
Epoch 1	Reward [-1.59 -1.73 -1.54 -1.61 -1.63]	Time 80.07s
Add-Rate: 0.10
Success: 0.82
Steps-taken: 20.00
Comm-Action: [0.77 0.77 0.78 0.77 0.78]
Epoch 2	Reward [-1.31 -1.29 -1.27 -1.26 -1.31]	Time 77.41s
Add-Rate: 0.10
Success: 0.84
Steps-taken: 20.00
Comm-Action: [0.82 0.82 0.82 0.82 0.82]
Epoch 3	Reward [-1.2  -1.14 -1.12 -1.15 -1.07]	Time 80.43s
Add-Rate: 0.10
Success: 0.83
Steps-taken: 20.00
Comm-Action: [0.89 0.89 0.89 0.89 0.89]
Epoch 4	Reward [-1.28 -1.11 -1.12 -1.15 -1.11]	Time 78.28s
Add-Rate: 0.10
Success: 0.84
Steps-taken: 20.00
Comm-Action: [0.85 0.85 0.85 0.85 0.85]
Epoch 5	Reward [-1.02 -1.06 -1.04 -1.04 -1.01]	Time 77.39s
Add-Rate: 0.10
Success: 0.85
Steps-taken: 20.00
Comm-Action: [0.89 0.89 0.89 0.89 0.89]
Epoch 6	Reward [-0.95 -0.94 -1.04 -0.96 -0.98]	Time 79.54s
Add-Rate: 0.10
Success: 0.85
Steps-taken: 20.00
Comm-Action: [0.92 0.92 0.92 0.92 0.92]
Epoch 7	Reward [-1.01 -1.06 -0.96 -1.01 -0.98]	Time 78.61s
Add-Rate: 0.10
Success: 0.83
Steps-taken: 20.00
Comm-Action: [0.94 0.94 0.94 0.94 0.94]
Epoch 8	Reward [-0.91 -0.98 -0.95 -0.93 -0.93]	Time 81.43s
Add-Rate: 0.10
Success: 0.84
Steps-taken: 20.00
Comm-Action: [0.95 0.95 0.95 0.95 0.95]
Epoch 9	Reward [-0.86 -1.   -0.92 -0.95 -0.92]	Time 75.49s
Add-Rate: 0.10
Success: 0.84
Steps-taken: 20.00
Comm-Action: [0.95 0.95 0.95 0.95 0.95]
Epoch 10	Reward [-0.9  -0.89 -0.93 -0.92 -0.86]	Time 76.00s
Add-Rate: 0.10
Success: 0.84
Steps-taken: 20.00
Comm-Action: [0.96 0.96 0.96 0.96 0.96]
Epoch 11	Reward [-0.82 -0.85 -0.86 -0.79 -0.79]	Time 77.30s
Add-Rate: 0.10
Success: 0.85
Steps-taken: 20.00
Comm-Action: [0.97 0.97 0.96 0.97 0.97]
Epoch 12	Reward [-0.9  -0.9  -0.89 -0.89 -0.86]	Time 78.63s
Add-Rate: 0.10
Success: 0.84
Steps-taken: 20.00
Comm-Action: [0.97 0.97 0.97 0.97 0.97]
Epoch 13	Reward [-0.87 -0.99 -0.84 -0.91 -0.9 ]	Time 79.01s
Add-Rate: 0.10
Success: 0.84
Steps-taken: 20.00
Comm-Action: [0.97 0.97 0.97 0.97 0.97]
Epoch 14	Reward [-0.78 -0.84 -0.79 -0.82 -0.86]	Time 78.70s
Add-Rate: 0.10
Success: 0.86
Steps-taken: 20.00
Comm-Action: [0.97 0.97 0.97 0.97 0.97]
Epoch 15	Reward [-0.81 -0.85 -0.9  -0.86 -0.87]	Time 77.96s
Add-Rate: 0.10
Success: 0.84
Steps-taken: 20.00
Comm-Action: [0.97 0.97 0.97 0.97 0.97]
Epoch 16	Reward [-0.93 -0.86 -0.86 -0.89 -0.86]	Time 79.09s
Add-Rate: 0.10
Success: 0.84
Steps-taken: 20.00
Comm-Action: [0.97 0.97 0.97 0.97 0.97]
Epoch 17	Reward [-0.84 -0.95 -0.88 -0.83 -0.87]	Time 77.91s
Add-Rate: 0.10
Success: 0.84
Steps-taken: 20.00
Comm-Action: [0.97 0.97 0.97 0.97 0.97]
Epoch 18	Reward [-0.84 -0.8  -0.88 -0.91 -0.87]	Time 80.34s
Add-Rate: 0.10
Success: 0.84
Steps-taken: 20.00
Comm-Action: [0.97 0.97 0.97 0.97 0.97]
Epoch 19	Reward [-0.82 -0.88 -0.88 -0.91 -0.91]	Time 78.90s
Add-Rate: 0.10
Success: 0.84
Steps-taken: 20.00
Comm-Action: [0.97 0.97 0.97 0.97 0.97]
Epoch 20	Reward [-0.83 -0.86 -0.82 -0.82 -0.88]	Time 79.46s
Add-Rate: 0.10
Success: 0.85
Steps-taken: 20.00
Comm-Action: [0.96 0.96 0.96 0.96 0.96]
Epoch 21	Reward [-1.01 -1.08 -1.05 -1.12 -1.  ]	Time 81.04s
Add-Rate: 0.10
Success: 0.85
Steps-taken: 20.00
Comm-Action: [0.88 0.88 0.87 0.88 0.88]
Epoch 22	Reward [-0.96 -0.99 -1.03 -1.   -0.99]	Time 78.29s
Add-Rate: 0.10
Success: 0.84
Steps-taken: 20.00
Comm-Action: [0.9 0.9 0.9 0.9 0.9]
Epoch 23	Reward [-0.97 -1.   -0.95 -1.   -0.95]	Time 79.84s
Add-Rate: 0.10
Success: 0.84
Steps-taken: 20.00
Comm-Action: [0.92 0.93 0.93 0.92 0.93]
Epoch 24	Reward [-0.86 -0.88 -0.86 -0.91 -0.89]	Time 77.09s
Add-Rate: 0.10
Success: 0.85
Steps-taken: 20.00
Comm-Action: [0.94 0.94 0.94 0.94 0.94]
Epoch 25	Reward [-0.94 -0.96 -0.92 -0.92 -0.92]	Time 80.57s
Add-Rate: 0.10
Success: 0.84
Steps-taken: 20.00
Comm-Action: [0.95 0.95 0.95 0.94 0.94]
Epoch 26	Reward [-0.93 -0.91 -0.93 -0.95 -0.95]	Time 77.20s
Add-Rate: 0.10
Success: 0.85
Steps-taken: 20.00
Comm-Action: [0.92 0.92 0.92 0.92 0.92]
Epoch 27	Reward [-1.06 -1.06 -1.03 -1.03 -1.09]	Time 76.41s
Add-Rate: 0.10
Success: 0.84
Steps-taken: 20.00
Comm-Action: [0.88 0.88 0.88 0.88 0.88]
Epoch 28	Reward [-1.13 -1.15 -1.09 -1.11 -1.12]	Time 78.66s
Add-Rate: 0.10
Success: 0.84
Steps-taken: 20.00
Comm-Action: [0.84 0.85 0.85 0.85 0.84]
Epoch 29	Reward [-1.01 -1.04 -1.01 -1.11 -1.06]	Time 77.34s
Add-Rate: 0.10
Success: 0.85
Steps-taken: 20.00
Comm-Action: [0.88 0.88 0.88 0.88 0.88]
