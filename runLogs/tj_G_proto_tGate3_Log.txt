env action space is:  Discrete(2)
num inputs is:  17
[2]
[2, 2]
Namespace(num_epochs=2000, epoch_size=10, batch_size=500, nprocesses=16, hid_size=128, recurrent=True, gamma=1.0, tau=1.0, seed=777, normalize_rewards=False, lrate=0.001, entr=0, value_coeff=0.01, env_name='traffic_junction', max_steps=20, nactions='1', action_scale=1.0, plot=False, plot_env='main', save='trained_models', save_every=100, load='trained_models', display=False, random=False, commnet=1, ic3net=True, nagents=5, comm_mode='avg', comm_passes=1, comm_mask_zero=False, mean_ratio=0, rnn_type='LSTM', detach_gap=10, comm_init='uniform', hard_attn=1, comm_action_one=False, comm_action_zero=False, advantages_per_action=False, share_weights=False, log_dir='tb_logs', exp_name='tj_G_proto_tGate3_', use_proto=True, discrete_comm=True, num_proto=25, comm_dim=16, gating_head_cost_factor=-0.1, restore=True, gate_reward_curriculum=False, gate_reward_max=-0.01, gate_reward_min=0.01, reward_curr_start=1500, reward_curr_end=1900, variable_gate=False, variable_gate_start=500, optim_name='RMSprop', dim=6, vision=0, add_rate_min=0.1, add_rate_max=0.3, curr_start=250.0, curr_end=1250.0, difficulty='easy', vocab_type='bool', nfriendly=5, num_actions=[2, 2], dim_actions=2, num_inputs=17, continuous=False, naction_heads=[2, 2])
using commnet
====================================================================================================
Model log:

CommNetMLP(
  (proto_layer): ProtoNetwork(
    (layers): ModuleList(
      (0): Linear(in_features=128, out_features=64, bias=True)
      (1): Linear(in_features=64, out_features=25, bias=True)
    )
    (prototype_layer): ProtoLayer()
  )
  (heads): ModuleList(
    (0): Linear(in_features=128, out_features=2, bias=True)
    (1): Linear(in_features=128, out_features=2, bias=True)
  )
  (encoder): Linear(in_features=17, out_features=16, bias=True)
  (hidd_encoder): Linear(in_features=128, out_features=128, bias=True)
  (f_module): LSTMCell(16, 128)
  (C_modules): ModuleList(
    (0): Linear(in_features=16, out_features=16, bias=True)
  )
  (tanh): Tanh()
  (value_head): Linear(in_features=128, out_features=1, bias=True)
)
====================================================================================================

Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
Device: cpu
DO NOT RUN THIS: AUTO REWARD CURRICULUM IN BETA
A
